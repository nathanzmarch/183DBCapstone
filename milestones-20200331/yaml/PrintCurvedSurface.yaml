- week: 1
  goals:
  - goal: A simulation of the world in which we will perform all future experiments in
    tasks: 
    - Follow the cyberbotics tutorials to get a general understanding of the Webots software
    - Create a new world
    deliverable: A video demonstration of the the world created using the Webots software, highlighting featurers of the world as well as the tools available to us.
    points: 2
  - goal: A robotic arm in the world
    tasks: 
    - Add a robotic arm to the world
    deliverable: Digital representations of the robotic arm highlighting design choices
    points: 2
  - goal: Test surfaces in world
    tasks: 
    - Add different objects to the world
    deliverable: Digital representations of various test surfaces
    points: 2
  - goal: Robot arm controlled movement
    tasks: 
    - Send commands to the robotic arm
    deliverable: Video demonstation of the arm reacting to basic commands
    points: 2
  - goal: Robot arm pencil attachment
    tasks: 
    - Attach pencil to robotic arm so it can draw
    deliverable: Video demonstation of the arm holding and drawing with a pencil
    points: 2
- week: 2
  goals:
  - goal: A working camera, pressure, and lidar Sensor
    tasks: 
    - Figure out how to add and get sensor output from the world
    - Add a camera sensor measuring the position of the robot
    - Add a pressure sensor measuring the pressure of the pencil on the paper
    - Add a lidar sensor measuring the distance from the camera to the robot arm
    deliverable: A video of a robot arm movements being measured by simulated sensors
    - A camera sensor measuring the position f the robot (2)
    - A pressure sensor measuring the pressure of the pencil on the paper (1)
    - A lidar sensor measuring the distance from the camera to the robot arm (1)
    points: 4
  - goal: Use OpenCV to localize arm if possible
    tasks: 
    - Determine whether OpenCV works well with simulated arm
    deliverable: Digital representations of OpenCV functionality with the simulation
    points: 2
  - goal: Calculate simulated error
    tasks: 
    - Determine expected position versus actual position after given commands
    - Add error to the robotic armâ€™s movement
    - Ensure sensors have some inaccuracies in their readings 
    deliverable: A video demonstrating simulated error
    - The robotic arm's movement should have noise/error (2)
    - The sensors should have inaccuracies in their readings (2)
    points: 4
- week: 3
  goals:
  - goal: Projection of a 2D image onto a 3D surface with reduced distortion
    tasks: 
    - Learn how to use Blender to map 2D images onto 3D surfaces
    - Learn how to use Render3D to turn pictures of 3D objects into digital models
    - Map a chosen 2D image onto a test surface to create a 3D projection.
    deliverable: A digital representation of
    - A 3D model generated by Render3D using a picture of a physical model (2)
    - A 3D projection of a 2D image onto a 3D test surface (3)
    points: 5
  - goal: A system that combines all simulated components into a cohesive whole
    tasks:
    - Combine all components: camera, canvas, robotic arm, pencil, and pressure/lidar sensors
    - Explore ideal camera set up: overhead vs. attached to the arm vs. a separate fixed position
    - Explore ideal placement for lidar and pressure sensors
    deliverable: A video demonstration of our final simulation set-up that combines all components
    - Camera, lidar, and pressure sensors should give meaningful data and efficiently capture all robot movements (2)
    - Robot arm should be able to draw basic lines using the pencil (2)
    points: 4
- week: 4
  goals:
  - goal: Simple 2D motion with reduced noise in the measurement and dynamics system
    tasks: 
    - Create a dynamics model of the simulated robotic arm
    - Create a measurement model of the sensors (camera, lidar, and pressure)
    - Design an Extended Kalman Filter (EKF) for state estimation
    - Create an algorithm that uses the estimated state and the ground truth (intended behavior) to make adjustments to the commands given to the robotic system.
    deliverable: A powerpoint presentation displaying
    - Our measurement and dynamic models (1)
    - Equations used in our models and EKF design (2)
    - An algorithm to generate commands to adjust for errors in movement (3)
    points: 6
    deliverable: A video of our simulated robot performing stable 2D motion
    - Noting corrective commands during the motion (3)
    - Containing log of estimated state vs. actual state for each time step (3)
    points: 6 
- week: 5
  goals:
  - goal: Simple 3D motion with reduced noise in the measurement and dynamics system
    tasks: 
    - Create a dynamics model of the simulated robotic arm
    - Create a measurement model of the sensors (camera, lidar, and pressure)
    - Design an Extended Kalman Filter (EKF) for state estimation
    - Create an algorithm that uses the estimated state and the ground truth (intended behavior) to make adjustments to the commands given to the robotic system.
    deliverable: A powerpoint presentation displaying
    - Our measurement and dynamic models (1)
    - Equations used in our models and EKF design (2)
    - An algorithm to generate commands to adjust for errors in movement (3)
    points: 6
    deliverable: A video of our simulated robot performing stable 3D motion
    - Noting corrective commands during the motion (3)
    - Containing log of estimated state vs. actual state for each time step (3)
    points: 6 
- week: 6
  goals:
  - goal: Detect image edges to break down a complex image into simple segments/lines
    tasks: 
    - Segment the image using an edge detector
    deliverable: The image of the result of edge detection applied to the image
    points: 3
  - goal: Reduce edge detection results into discrete points
    tasks: 
    - Find the best mask to convolve image with to get discrete points from edge detection
    - Use a filter to extract points of instruction
    deliverable: The image after getting discrete points to interpolate between
    points: 3
  - goal: Projection of resulting discrete points onto a 3D surface
    tasks: 
    - Use the same 2D-3D mapping found in week 3 to map the discrete instruction points to 3D surface
    deliverable: The resulting 3D image after projection onto our 3D model
    points: 2
  - goal: Generate instruction sets for each 3D mapped segment
    tasks:
    - Generate instructions from extracted points
    deliverable: A list of instruction from the 3D image
    points: 2
- week: 7
  goals:
  - goal: To be able to draw an entire image given multiple segment instruction sets
    tasks: 
    - Send instruction sets to the 3D robot to draw all of the segments to form the image
    deliverable: A video of the robot drawing the image
    points: 5
  - goal: Good alignment between segments and minimal error
    tasks: 
    - Try to incorporate the pressure sensor into our interpolation algorithm so the arm stays on the surface
    deliverable: The algorithm we used for interpolating between points
    points: 5
- week: 8
  goals:
  - goal: Reduced error in image drawing
    tasks: 
    - Try alternative techniques to reduce error in the system
    deliverable: Video comparing the drawing done from the previous week and this week
    points: 5
  - goal: Improved speed and/or accuracy, with balanced tradeoffs
    tasks: 
    - Explore alternate techniques to improve speed and accuracy, and balance tradeoffs
    deliverable: Description of changes made for improvements
    points: 5
  - goal: Summarize dependencies and expected conclusions
    tasks:
    - Formalize our dependencies and expected conclusions
    deliverable: A list of dependencies and expected conclusions
    points: 3
- week: 9
  goals:
  - goal: goal A
    tasks: 
    - Task A
    deliverable: deliverable A
    points: 10
- week: 10
  goals:
  - goal: goal A
    tasks: 
    - Task A
    deliverable: deliverable A
    points: 10
